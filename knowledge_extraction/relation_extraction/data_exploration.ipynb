{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset('docred', trust_remote_code=True)\n",
    "annotated = pd.DataFrame(dataset['train_annotated'])\n",
    "distant = pd.DataFrame(dataset['train_distant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['title', 'sents', 'vertexSet', 'labels'],\n",
      "        num_rows: 998\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['title', 'sents', 'vertexSet', 'labels'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train_annotated: Dataset({\n",
      "        features: ['title', 'sents', 'vertexSet', 'labels'],\n",
      "        num_rows: 3053\n",
      "    })\n",
      "    train_distant: Dataset({\n",
      "        features: ['title', 'sents', 'vertexSet', 'labels'],\n",
      "        num_rows: 101873\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data Format:\n",
    "(source: https://github.com/thunlp/DocRED/blob/master/data/README.md)\n",
    "{\n",
    "  'title',\n",
    "  'sents':     [\n",
    "                  [word in sent 0], # list of lists of words forming sentences\n",
    "                  [word in sent 1]\n",
    "               ]\n",
    "  'vertexSet': [\n",
    "                  [\n",
    "                    { 'name': mention_name, # name of entity mention\n",
    "                      'sent_id': mention in which sentence, --> index of the sentence where the mention occurs\n",
    "                      'pos': postion of mention in a sentence,  --> start and end position (indices) of the mention in the sentence\n",
    "                      'type': NER_type} #the NER type, e.g. PERSON, LOCATION\n",
    "                    {anthor mention}\n",
    "                  ], \n",
    "                  [anthoer entity]\n",
    "                ]\n",
    "  'labels':   [\n",
    "                {\n",
    "                  'h': idx of head entity in vertexSet,\n",
    "                  't': idx of tail entity in vertexSet,\n",
    "                  'r': relation,\n",
    "                  'evidence': evidence sentences' id --> the sentences from which the relation is supported\n",
    "                }\n",
    "              ]\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zest Airways , Inc. operated as AirAsia Zest ( formerly Asian Spirit and Zest Air ) , was a low - cost airline based at the Ninoy Aquino International Airport in Pasay City , Metro Manila in the Philippines .\n",
      "It operated scheduled domestic and international tourist services , mainly feeder services linking Manila and Cebu with 24 domestic destinations in support of the trunk route operations of other airlines .\n",
      "In 2013 , the airline became an affiliate of Philippines AirAsia operating their brand separately .\n",
      "Its main base was Ninoy Aquino International Airport , Manila .\n",
      "The airline was founded as Asian Spirit , the first airline in the Philippines to be run as a cooperative .\n",
      "On August 16 , 2013 , the Civil Aviation Authority of the Philippines ( CAAP ) , the regulating body of the Government of the Republic of the Philippines for civil aviation , suspended Zest Air flights until further notice because of safety issues .\n",
      "Less than a year after AirAsia and Zest Air 's strategic alliance , the airline has been rebranded as AirAsia Zest .\n",
      "The airline was merged into AirAsia Philippines in January 2016 .\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import _RE\n",
    "importlib.reload(_RE)\n",
    "from _RE import join_text\n",
    "\n",
    "sents = annotated.iloc[0]['sents']\n",
    "text = join_text(sents, fancy=False)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_triplets(vertexSet, labels):\n",
    "    '''\n",
    "    Returns a triplet of format <head, relation, tail>\n",
    "    '''\n",
    "\n",
    "    names = []\n",
    "    types = []\n",
    "    triplets = []\n",
    "\n",
    "    head = labels['head']\n",
    "    tail = labels['tail']\n",
    "    relation = labels['relation_id']\n",
    "    relation_names = labels['relation_text']\n",
    "\n",
    "    for entities in vertexSet:\n",
    "        sub_names = []\n",
    "        sub_types = []\n",
    "        for entity in entities:\n",
    "            sub_names.append(entity['name'])\n",
    "            sub_types.append(entity['type'])\n",
    "        names.append(sub_names)\n",
    "        types.append(sub_types)\n",
    "\n",
    "    for i in range(len(labels['head'])):\n",
    "        triplets.append([names[head[i]], [relation[i], relation_names[i]], names[tail[i]]])\n",
    "    \n",
    "    for t in triplets:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Zest Airways, Inc.', 'Asian Spirit and Zest Air', 'AirAsia Zest', 'AirAsia Zest'], ['P159', 'headquarters location'], ['Pasay City']]\n",
      "[['Zest Airways, Inc.', 'Asian Spirit and Zest Air', 'AirAsia Zest', 'AirAsia Zest'], ['P17', 'country'], ['Philippines', 'Philippines', 'Republic of the Philippines']]\n",
      "[['Zest Air', 'Zest Air'], ['P17', 'country'], ['Philippines', 'Philippines', 'Republic of the Philippines']]\n",
      "[['Pasay City'], ['P17', 'country'], ['Philippines', 'Philippines', 'Republic of the Philippines']]\n",
      "[['Pasay City'], ['P131', 'located in the administrative territorial entity'], ['Metro Manila']]\n",
      "[['Philippines', 'Philippines', 'Republic of the Philippines'], ['P150', 'contains administrative territorial entity'], ['Metro Manila']]\n",
      "[['Manila', 'Manila'], ['P17', 'country'], ['Philippines', 'Philippines', 'Republic of the Philippines']]\n",
      "[['Metro Manila'], ['P150', 'contains administrative territorial entity'], ['Pasay City']]\n",
      "[['Metro Manila'], ['P131', 'located in the administrative territorial entity'], ['Philippines', 'Philippines', 'Republic of the Philippines']]\n",
      "[['Metro Manila'], ['P17', 'country'], ['Philippines', 'Philippines', 'Republic of the Philippines']]\n",
      "[['Ninoy Aquino International Airport', 'Ninoy Aquino International Airport'], ['P131', 'located in the administrative territorial entity'], ['Pasay City']]\n",
      "[['Ninoy Aquino International Airport', 'Ninoy Aquino International Airport'], ['P17', 'country'], ['Philippines', 'Philippines', 'Republic of the Philippines']]\n",
      "[['Asian Spirit'], ['P17', 'country'], ['Philippines', 'Philippines', 'Republic of the Philippines']]\n"
     ]
    }
   ],
   "source": [
    "'''print(annotated.columns)\n",
    "vertexSet = annotated['vertexSet'][0]\n",
    "for subset in vertexSet:\n",
    "    print (subset)\n",
    "labels = annotated.iloc[0]['labels']\n",
    "for l in labels:\n",
    "    print(l, labels[l])'''\n",
    "\n",
    "make_triplets(vertexSet, labels)\n",
    "\n",
    "# The first triplet here makes no sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'sents', 'vertexSet', 'labels'], dtype='object')\n",
      "[{'name': 'Jackie Beat', 'sent_id': 0, 'pos': [0, 2], 'type': 'PER'}, {'name': 'Kent Fuher', 'sent_id': 0, 'pos': [21, 23], 'type': 'PER'}, {'name': 'Jackie Beat', 'sent_id': 4, 'pos': [0, 2], 'type': 'PER'}, {'name': 'Beat', 'sent_id': 1, 'pos': [0, 1], 'type': 'PER'}, {'name': 'Beat', 'sent_id': 2, 'pos': [3, 4], 'type': 'PER'}, {'name': 'Beat', 'sent_id': 5, 'pos': [0, 1], 'type': 'PER'}, {'name': 'Beat', 'sent_id': 6, 'pos': [0, 1], 'type': 'PER'}, {'name': 'Beat', 'sent_id': 3, 'pos': [0, 1], 'type': 'PER'}]\n",
      "[{'name': 'July 24, 1965', 'sent_id': 0, 'pos': [4, 8], 'type': 'TIME'}]\n",
      "[{'name': 'Flawless', 'sent_id': 1, 'pos': [19, 20], 'type': 'MISC'}]\n",
      "[{'name': 'Adam & Steve', 'sent_id': 1, 'pos': [22, 25], 'type': 'MISC'}]\n",
      "[{'name': 'Dance Off', 'sent_id': 1, 'pos': [36, 38], 'type': 'MISC'}]\n",
      "[{'name': 'Sex and the City', 'sent_id': 2, 'pos': [7, 11], 'type': 'MISC'}]\n",
      "[{'name': 'Hype', 'sent_id': 2, 'pos': [23, 24], 'type': 'MISC'}]\n",
      "[{'name': 'WB Television Network', 'sent_id': 2, 'pos': [26, 29], 'type': 'ORG'}]\n",
      "[{'name': 'New York City', 'sent_id': 3, 'pos': [6, 9], 'type': 'LOC'}]\n",
      "[{'name': 'Christmas', 'sent_id': 3, 'pos': [24, 25], 'type': 'MISC'}, {'name': 'Christmas', 'sent_id': 3, 'pos': [32, 33], 'type': 'MISC'}]\n",
      "[{'name': '2009', 'sent_id': 3, 'pos': [30, 31], 'type': 'TIME'}]\n",
      "[{'name': 'Laurie Beechman Theater', 'sent_id': 3, 'pos': [38, 41], 'type': 'LOC'}]\n",
      "[{'name': 'Electroclash', 'sent_id': 4, 'pos': [8, 9], 'type': 'ORG'}]\n",
      "[{'name': 'Dirty Sanchez', 'sent_id': 4, 'pos': [10, 12], 'type': 'ORG'}]\n",
      "[{'name': 'IN : LA', 'sent_id': 5, 'pos': [6, 9], 'type': 'MISC'}]\n",
      "[{'name': 'Highland Park', 'sent_id': 6, 'pos': [3, 5], 'type': 'LOC'}]\n",
      "[{'name': 'California', 'sent_id': 6, 'pos': [6, 7], 'type': 'LOC'}]\n",
      "head [0, 6, 15, 13, 13]\n",
      "tail [1, 7, 16, 0, 12]\n",
      "relation_id ['P569', 'P449', 'P131', 'P527', 'P136']\n",
      "relation_text ['date of birth', 'original network', 'located in the administrative territorial entity', 'has part', 'genre']\n",
      "evidence [[0], [2], [6], [4], [4]]\n"
     ]
    }
   ],
   "source": [
    "print(annotated.columns)\n",
    "N = 61\n",
    "vertexSet = annotated['vertexSet'][N]\n",
    "for subset in vertexSet:\n",
    "    print (subset)\n",
    "labels = annotated.iloc[N]['labels']\n",
    "for l in labels:\n",
    "    print(l, labels[l])\n",
    "\n",
    "# The first triplet here makes no sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filenames = [\n",
    "    #'docred_metadata/char2id.json',\n",
    "    #'docred_metadata/ner2id.json',\n",
    "    #'docred_metadata/rel2id.json',\n",
    "    #'docred_metadata/word2id.json',\n",
    "    'docred_metadata/rel_info.json'\n",
    "    ]\n",
    "\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 96\n",
      "1. P6: head of government\n",
      "2. P17: country\n",
      "3. P19: place of birth\n",
      "4. P20: place of death\n",
      "5. P22: father\n",
      "6. P25: mother\n",
      "7. P26: spouse\n",
      "8. P27: country of citizenship\n",
      "9. P30: continent\n",
      "10. P31: instance of\n",
      "11. P35: head of state\n",
      "12. P36: capital\n",
      "13. P37: official language\n",
      "14. P39: position held\n",
      "15. P40: child\n",
      "16. P50: author\n",
      "17. P54: member of sports team\n",
      "18. P57: director\n",
      "19. P58: screenwriter\n",
      "20. P69: educated at\n",
      "21. P86: composer\n",
      "22. P102: member of political party\n",
      "23. P108: employer\n",
      "24. P112: founded by\n",
      "25. P118: league\n",
      "26. P123: publisher\n",
      "27. P127: owned by\n",
      "28. P131: located in the administrative territorial entity\n",
      "29. P136: genre\n",
      "30. P137: operator\n",
      "31. P140: religion\n",
      "32. P150: contains administrative territorial entity\n",
      "33. P155: follows\n",
      "34. P156: followed by\n",
      "35. P159: headquarters location\n",
      "36. P161: cast member\n",
      "37. P162: producer\n",
      "38. P166: award received\n",
      "39. P170: creator\n",
      "40. P171: parent taxon\n",
      "41. P172: ethnic group\n",
      "42. P175: performer\n",
      "43. P176: manufacturer\n",
      "44. P178: developer\n",
      "45. P179: series\n",
      "46. P190: sister city\n",
      "47. P194: legislative body\n",
      "48. P205: basin country\n",
      "49. P206: located in or next to body of water\n",
      "50. P241: military branch\n",
      "51. P264: record label\n",
      "52. P272: production company\n",
      "53. P276: location\n",
      "54. P279: subclass of\n",
      "55. P355: subsidiary\n",
      "56. P361: part of\n",
      "57. P364: original language of work\n",
      "58. P400: platform\n",
      "59. P403: mouth of the watercourse\n",
      "60. P449: original network\n",
      "61. P463: member of\n",
      "62. P488: chairperson\n",
      "63. P495: country of origin\n",
      "64. P527: has part\n",
      "65. P551: residence\n",
      "66. P569: date of birth\n",
      "67. P570: date of death\n",
      "68. P571: inception\n",
      "69. P576: dissolved, abolished or demolished\n",
      "70. P577: publication date\n",
      "71. P580: start time\n",
      "72. P582: end time\n",
      "73. P585: point in time\n",
      "74. P607: conflict\n",
      "75. P674: characters\n",
      "76. P676: lyrics by\n",
      "77. P706: located on terrain feature\n",
      "78. P710: participant\n",
      "79. P737: influenced by\n",
      "80. P740: location of formation\n",
      "81. P749: parent organization\n",
      "82. P800: notable work\n",
      "83. P807: separated from\n",
      "84. P840: narrative location\n",
      "85. P937: work location\n",
      "86. P1001: applies to jurisdiction\n",
      "87. P1056: product or material produced\n",
      "88. P1198: unemployment rate\n",
      "89. P1336: territory claimed by\n",
      "90. P1344: participant of\n",
      "91. P1365: replaces\n",
      "92. P1366: replaced by\n",
      "93. P1376: capital of\n",
      "94. P1412: languages spoken, written or signed\n",
      "95. P1441: present in work\n",
      "96. P3373: sibling\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open ('docred_metadata/rel_info.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print('Number of classes:', len(data))\n",
    "for i, key in enumerate(data):\n",
    "    print(f\"{i+1}. {key}: {data[key]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
