{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset('docred', trust_remote_code=True)\n",
    "annotated = pd.DataFrame(dataset['train_annotated'])\n",
    "distant = pd.DataFrame(dataset['train_distant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdataset\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data Format:\n",
    "(source: https://github.com/thunlp/DocRED/blob/master/data/README.md)\n",
    "{\n",
    "  'title',\n",
    "  'sents':     [\n",
    "                  [word in sent 0], # list of lists of words forming sentences\n",
    "                  [word in sent 1]\n",
    "               ]\n",
    "  'vertexSet': [\n",
    "                  [\n",
    "                    { 'name': mention_name, # name of entity mention\n",
    "                      'sent_id': mention in which sentence, --> index of the sentence where the mention occurs\n",
    "                      'pos': postion of mention in a sentence,  --> start and end position (indices) of the mention in the sentence\n",
    "                      'type': NER_type} #the NER type, e.g. PERSON, LOCATION\n",
    "                    {anthor mention}\n",
    "                  ], \n",
    "                  [anthoer entity]\n",
    "                ]\n",
    "  'labels':   [\n",
    "                {\n",
    "                  'h': idx of head entity in vertexSet,\n",
    "                  't': idx of tail entity in vertexSet,\n",
    "                  'r': relation,\n",
    "                  'evidence': evidence sentences' id --> the sentences from which the relation is supported\n",
    "                }\n",
    "              ]\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zest Airways , Inc. operated as AirAsia Zest ( formerly Asian Spirit and Zest Air ) , was a low - cost airline based at the Ninoy Aquino International Airport in Pasay City , Metro Manila in the Philippines .\n",
      "It operated scheduled domestic and international tourist services , mainly feeder services linking Manila and Cebu with 24 domestic destinations in support of the trunk route operations of other airlines .\n",
      "In 2013 , the airline became an affiliate of Philippines AirAsia operating their brand separately .\n",
      "Its main base was Ninoy Aquino International Airport , Manila .\n",
      "The airline was founded as Asian Spirit , the first airline in the Philippines to be run as a cooperative .\n",
      "On August 16 , 2013 , the Civil Aviation Authority of the Philippines ( CAAP ) , the regulating body of the Government of the Republic of the Philippines for civil aviation , suspended Zest Air flights until further notice because of safety issues .\n",
      "Less than a year after AirAsia and Zest Air 's strategic alliance , the airline has been rebranded as AirAsia Zest .\n",
      "The airline was merged into AirAsia Philippines in January 2016 .\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import _RE\n",
    "importlib.reload(_RE)\n",
    "from _RE import join_text, make_triplets\n",
    "\n",
    "sents = annotated.iloc[0]['sents']\n",
    "text = join_text(sents, fancy=False)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mississippi River'], ['P131', 'located in the administrative territorial entity'], ['Illinois']]\n",
      "[['Mississippi River'], ['P17', 'country'], ['United States']]\n",
      "[['Madison County'], ['P131', 'located in the administrative territorial entity'], ['Illinois']]\n",
      "[['Madison County'], ['P17', 'country'], ['United States']]\n",
      "[['Illinois'], ['P206', 'located in or next to body of water'], ['Mississippi River']]\n",
      "[['Illinois'], ['P150', 'contains administrative territorial entity'], ['Madison County']]\n",
      "[['Illinois'], ['P131', 'located in the administrative territorial entity'], ['United States']]\n",
      "[['Illinois'], ['P17', 'country'], ['United States']]\n",
      "[['United States'], ['P150', 'contains administrative territorial entity'], ['Illinois']]\n",
      "[['United States'], ['P150', 'contains administrative territorial entity'], ['Missouri']]\n",
      "[['Missouri'], ['P131', 'located in the administrative territorial entity'], ['United States']]\n",
      "[['Missouri'], ['P17', 'country'], ['United States']]\n",
      "[['Greater St. Louis', 'St. Louis'], ['P17', 'country'], ['United States']]\n",
      "[['American Civil War', 'Civil War'], ['P17', 'country'], ['United States']]\n",
      "[['American Civil War', 'Civil War'], ['P495', 'country of origin'], ['United States']]\n",
      "[['Miles Davis'], ['P27', 'country of citizenship'], ['United States']]\n",
      "[['Miles Davis'], ['P19', 'place of birth'], ['Alton', 'Alton']]\n",
      "[['Robert Wadlow'], ['P27', 'country of citizenship'], ['United States']]\n",
      "[['Robert Wadlow'], ['P19', 'place of birth'], ['Alton', 'Alton']]\n",
      "[['Robert Wadlow'], ['P551', 'residence'], ['Alton', 'Alton']]\n",
      "[['Metro - East'], ['P17', 'country'], ['United States']]\n",
      "[['Alton', 'Alton'], ['P131', 'located in the administrative territorial entity'], ['Madison County']]\n",
      "[['Alton', 'Alton'], ['P17', 'country'], ['United States']]\n"
     ]
    }
   ],
   "source": [
    "index = 6\n",
    "labels = annotated.iloc[index]['labels']\n",
    "vertexSet = annotated['vertexSet'][index]\n",
    "\n",
    "'''print(annotated.columns)\n",
    "for subset in vertexSet:\n",
    "    print (subset)\n",
    "for l in labels:\n",
    "    print(l, labels[l])'''\n",
    "\n",
    "triplet = make_triplets(vertexSet, labels)\n",
    "\n",
    "for t in triplet:\n",
    "    print(t)\n",
    "\n",
    "# The first triplet here makes no sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filenames = [\n",
    "    #'docred_metadata/char2id.json',\n",
    "    #'docred_metadata/ner2id.json',\n",
    "    #'docred_metadata/rel2id.json',\n",
    "    #'docred_metadata/word2id.json',\n",
    "    'docred_metadata/rel_info.json'\n",
    "    ]\n",
    "\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 96\n",
      "1. P6: head of government\n",
      "2. P17: country\n",
      "3. P19: place of birth\n",
      "4. P20: place of death\n",
      "5. P22: father\n",
      "6. P25: mother\n",
      "7. P26: spouse\n",
      "8. P27: country of citizenship\n",
      "9. P30: continent\n",
      "10. P31: instance of\n",
      "11. P35: head of state\n",
      "12. P36: capital\n",
      "13. P37: official language\n",
      "14. P39: position held\n",
      "15. P40: child\n",
      "16. P50: author\n",
      "17. P54: member of sports team\n",
      "18. P57: director\n",
      "19. P58: screenwriter\n",
      "20. P69: educated at\n",
      "21. P86: composer\n",
      "22. P102: member of political party\n",
      "23. P108: employer\n",
      "24. P112: founded by\n",
      "25. P118: league\n",
      "26. P123: publisher\n",
      "27. P127: owned by\n",
      "28. P131: located in the administrative territorial entity\n",
      "29. P136: genre\n",
      "30. P137: operator\n",
      "31. P140: religion\n",
      "32. P150: contains administrative territorial entity\n",
      "33. P155: follows\n",
      "34. P156: followed by\n",
      "35. P159: headquarters location\n",
      "36. P161: cast member\n",
      "37. P162: producer\n",
      "38. P166: award received\n",
      "39. P170: creator\n",
      "40. P171: parent taxon\n",
      "41. P172: ethnic group\n",
      "42. P175: performer\n",
      "43. P176: manufacturer\n",
      "44. P178: developer\n",
      "45. P179: series\n",
      "46. P190: sister city\n",
      "47. P194: legislative body\n",
      "48. P205: basin country\n",
      "49. P206: located in or next to body of water\n",
      "50. P241: military branch\n",
      "51. P264: record label\n",
      "52. P272: production company\n",
      "53. P276: location\n",
      "54. P279: subclass of\n",
      "55. P355: subsidiary\n",
      "56. P361: part of\n",
      "57. P364: original language of work\n",
      "58. P400: platform\n",
      "59. P403: mouth of the watercourse\n",
      "60. P449: original network\n",
      "61. P463: member of\n",
      "62. P488: chairperson\n",
      "63. P495: country of origin\n",
      "64. P527: has part\n",
      "65. P551: residence\n",
      "66. P569: date of birth\n",
      "67. P570: date of death\n",
      "68. P571: inception\n",
      "69. P576: dissolved, abolished or demolished\n",
      "70. P577: publication date\n",
      "71. P580: start time\n",
      "72. P582: end time\n",
      "73. P585: point in time\n",
      "74. P607: conflict\n",
      "75. P674: characters\n",
      "76. P676: lyrics by\n",
      "77. P706: located on terrain feature\n",
      "78. P710: participant\n",
      "79. P737: influenced by\n",
      "80. P740: location of formation\n",
      "81. P749: parent organization\n",
      "82. P800: notable work\n",
      "83. P807: separated from\n",
      "84. P840: narrative location\n",
      "85. P937: work location\n",
      "86. P1001: applies to jurisdiction\n",
      "87. P1056: product or material produced\n",
      "88. P1198: unemployment rate\n",
      "89. P1336: territory claimed by\n",
      "90. P1344: participant of\n",
      "91. P1365: replaces\n",
      "92. P1366: replaced by\n",
      "93. P1376: capital of\n",
      "94. P1412: languages spoken, written or signed\n",
      "95. P1441: present in work\n",
      "96. P3373: sibling\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open ('docred_metadata/rel_info.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print('Number of classes:', len(data))\n",
    "for i, key in enumerate(data):\n",
    "    print(f\"{i+1}. {key}: {data[key]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
