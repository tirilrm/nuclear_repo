{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "World Nuclear News: https://www.world-nuclear-news.org/\n",
    "\n",
    "New Civil Engineer: https://www.newcivilengineer.com/\n",
    "\n",
    "Nuclear Engineering International: https://www.neimagazine.com/\n",
    "\n",
    "Nucnet: https://www.nucnet.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# World Nuclear News: https://www.world-nuclear-news.org/\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.world-nuclear-news.org/search.aspx?searchtext=%22small+modular+reactor%22&searchmode=anyword')\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "page = 0\n",
    "\n",
    "with open('WNN_urls.txt', 'w') as file:\n",
    "\n",
    "    while(page <= 51): # 51 pages in total\n",
    "        for i in range(8):\n",
    "            try:\n",
    "                element = driver.find_element(By.XPATH, f'//*[@id=\"ctl00_ContentPlaceHolder1_PlaceHolderZones_lt_SearchResults_SmartSearchResults_srchResults_pnlSearchResults\"]/div[{i+1}]/div/a')\n",
    "            except NoSuchElementException:\n",
    "                element = None\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "            if(element):\n",
    "                href = element.get_attribute('href')\n",
    "                file.write(href + '\\n')\n",
    "                print(href)\n",
    "        \n",
    "        try:\n",
    "            driver.find_element(By.XPATH, '//*[@id=\"ctl00_ContentPlaceHolder1_PlaceHolderZones_lt_SearchResults_SmartSearchResults_srchResults_pnlSearchResults\"]/a[13]').click()\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "        \n",
    "        time.sleep(1)\n",
    "        page += 1\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Civil Engineer: https://www.newcivilengineer.com/ \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.newcivilengineer.com/?s=%22small+modular+reactor%22')\n",
    "\n",
    "#time.sleep(1)\n",
    "\n",
    "page = 0\n",
    "with open('NCE_urls.txt', 'w') as file:\n",
    "\n",
    "    while(page < 18): # 18 pages in total\n",
    "\n",
    "        if page == 0:\n",
    "            driver.find_element(By.XPATH, '//*[@id=\"top\"]/div[11]/div[2]/div[1]/div[2]/div[2]/button[1]/p').click()\n",
    "\n",
    "        \n",
    "        for i in range(8):\n",
    "            try:\n",
    "                element = driver.find_element(By.XPATH, f'//*[@id=\"main-content\"]/div[2]/div[3]/article[{i+1}]/h2/a')\n",
    "            except NoSuchElementException:\n",
    "                element = None\n",
    "\n",
    "            #time.sleep(1)\n",
    "\n",
    "            if(element):\n",
    "                href = element.get_attribute('href')\n",
    "                file.write(href + '\\n')\n",
    "                #print(href)\n",
    "        \n",
    "        try:\n",
    "            driver.get(f'https://www.newcivilengineer.com/page/{page + 2}/?s=%22small+modular+reactor%22')\n",
    "            print(f\"Clicked {page +1} times\")\n",
    "        except NoSuchElementException:\n",
    "            print(\"Nope\")\n",
    "            break\n",
    "        \n",
    "        #time.sleep(1)\n",
    "        page += 1\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Nuclear Engineering International: https://www.neimagazine.com/\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.neimagazine.com/?s=%22small+modular+reactor%22')\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "i = 1\n",
    "with open('NEI_urls_long.txt', 'w') as file:\n",
    "\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    i=0\n",
    "    while(i<10000): # Get full length, max 1000\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "        if i%50 == 0:\n",
    "            print(i)\n",
    "        i = i+1\n",
    "\n",
    "    print(\"Scroll done. Sleeping for 5...\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    articles = driver.find_elements(By.XPATH, \"//a[@href and @title]\")\n",
    "    for i, article in enumerate(articles):\n",
    "        href = article.get_attribute('href')\n",
    "        if 'news' in href or 'analysis' in href and i > 20:\n",
    "            file.write(href + '\\n')\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on NEI Magazine:\n",
    "- 500 scrolls\n",
    "- ~3400 urls\n",
    "- time: approx. 16 min\n",
    "- last entry: January 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NucNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on Nucnet\n",
    "- behind wall, requested free trial\n",
    "- OK to scrape with account in Imperial's name? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
